# rag-doc-qa

What problem does Retrieval-Augmented Generation (RAG) aim to solve in knowledge-intensive NLP tasks?


How does RAG combine parametric and non-parametric memory?


What is the difference between RAG-Sequence and RAG-Token models?


How are retrieved documents treated during training in RAG?


What are Thorough Decoding and Fast Decoding, and why are they needed in RAG-Sequence?


What is the main idea behind the Transformer architecture proposed in the paper?


How does self-attention differ from recurrent neural networks?


What is scaled dot-product attention, and why is scaling used?


What role does multi-head attention play in the Transformer?


Why does the Transformer model allow better parallelization than RNN-based models?


How does the novel introduce the theme of marriage in the opening chapter?


What is Mr. Bennetâ€™s attitude toward his family and society?


How is Elizabeth Bennet characterized in the early chapters?


What role does social class play in the interactions between characters?


How does Jane Austen use irony in Pride and Prejudice?


How does Alice first enter Wonderland?


What role does the White Rabbit play in the story?


How does Alice react to changes in her size?


What kinds of logical or language-based absurdities appear in Wonderland?


How does the story challenge normal rules of reality and behavior?